---
execute:
  eval: false
---

# Preliminary Analysis 2

```{r}
#| label: setup
#| include: false

library(here)

source(here("R", "_setup.R"))
```

## Set the Environment

```{r}
#| output: false

library(actverse) # github.com/danielvartan/actverse
library(askpass)
library(broom)
library(checkmate)
library(cli)
library(effectsize)
library(fs)
library(ggplot2)
library(googlesheets4)
library(here)
library(hms)
library(infer)
library(janitor)
library(lockr) # github.com/danielvartan/lockr
library(lubridate)
library(lubritime) # github.com/danielvartan/lubritime
library(magrittr)
library(orbis) # github.com/danielvartan/orbis
library(osfr)
library(parsnip)
library(plotr) # github.com/danielvartan/plotr
library(prettycheck) # github.com/danielvartan/prettycheck
library(psychometric)
library(pwr)
library(pwrss)
library(readr)
library(rutils) # github.com/danielvartan/rutils
library(scaler) # github.com/danielvartan/scaler
library(scales)
library(sodium)
library(stats)
library(stringr)
library(summarytools)
library(tidyr)
library(tsibble)
```

```{r}
source(here("R", "anonymize_id.R"))
source(here("R", "ga.R"))
```

## Setting Parameters

```{r}
#| eval: false
#| output: false

assert_interactive()
gs4_auth()
```

```{r}
#| eval: false

assert_interactive()
osf_auth()
```

```{r}
private_key_path <- here("_ssh", "id_rsa")
```

```{r}
#| eval: false

password <- askpass()
```

```{r}
#| eval: false

salt <- askpass()
```

```{r}
public_key_path <- here("_ssh", "id_rsa.pub")
```


## *A Priori* Power Analysis

```{r}
set.seed(2025)
```

```{r}
n_clusters <- 66 # Number of participants
cluster_size <- 2 # Average number of weeks per participant
alpha <- 0.3 # Intra-class correlation
beta <- - 2 # Effect size (per week)
sigma <- 5 # Standard deviation of the outcome

type_one_error <- 0.05

n_sim <- 1000
rejects <- 0

for (i in seq_len(n_sim)){
  sim_data <- tibble(
    id = seq_len(n_clusters) |> rep(each = cluster_size),
    x = seq_len(cluster_size) |> rep(n_clusters)
  )

  correlated_errors <-
    rep(
      rnorm(n_clusters, 0, sigma * sqrt(alpha)),
      each = cluster_size
    ) |>
    add(
      rnorm(n_clusters * cluster_size, 0, sigma * sqrt(1 - alpha))
    )

  sim_data <- sim_data |> mutate(y = beta * x + correlated_errors)

  fit <- geeglm(
    y ~ x,
    family = gaussian,
    id = id,
    data = sim_data,
    corstr = "exchangeable"
  )

  p_value <- summary(fit)$coefficients[2,4]

  if (p_value < type_one_error) rejects <- rejects + 1
}

power_estimate <- rejects / n_sim

power_estimate
```

## Get Data from Google Sheets

```{r}
#| output: false

control_form <- read_sheet(
  ss = "13wtDr4fRD1wJSM-qdLOdGSchF8oXU1bG0Jtccu24GhY",
  sheet = "Dataset",
  col_types = "c"
)
```

```{r}
#| output: false

field_form <- read_sheet(
  ss = "1tY_TT0nPXFsErYQS2VED0-hqTzgHudA9BfhRhYG19fw",
  sheet = "Dataset",
  col_types = "c"
)
```

## Process the Google Sheets Data

```{r}
control_data <-
  control_form |>
  `names<-`(paste0("X", seq_along(control_form))) |>
  dplyr::select(X5, X6, X12, X39, X40) |>
  rename(
    cpf = X5,
    id = X6,
    birth_center_delivery = X12,
    ultrasound_date = X40,
    ultrasound_ga = X39
  ) |>
  mutate(
    birth_center_delivery = case_when(
      tolower(trimws(birth_center_delivery)) == "sim" ~ TRUE,
      tolower(trimws(birth_center_delivery)) == "não" ~ FALSE,
      TRUE ~ NA
    ),
    ultrasound_date = ymd(ultrasound_date),
    ga_start = if_else(
      is.na(ultrasound_ga),
      as.Date(NA),
      ga_start(
        ultrasound = ultrasound_date,
        ga =
          str_extract(ultrasound_ga, "^\\d{1,2}") |>
          as.integer() |>
          weeks() |>
          add(
            str_extract(ultrasound_ga, "\\d(?= di)") |>
            as.integer() |>
            days()
          )
      )
    )
  ) |>
  dplyr::select(cpf, id, birth_center_delivery, ga_start)

control_data
```

```{r}
field_form_data <-
  field_form |>
  `names<-`(paste0("X", seq_along(field_form))) |>
  dplyr::select(
    X1, X4, X5, X11, X91, X92, X95, X96, X97, X99, X101, X102, X106, X119,
    X118, X125, X126
  ) |>
  rename(
    timestamp = X1,
    birth_date = X4,
    cpf = X5,
    weight_before = X96,
    weight_current = X95,
    height = X97,
    ethnicity = X106,
    education = X118,
    family_income = X99,
    health_plan = X101,
    solo = X102,
    exercise = X119,
    work = X92,
    study = X91,
    gestations = X11,
    deliveries = X125,
    abortions = X126
  ) |>
  mutate(
    id = anonymize_id(cpf, salt),
    timestamp = mdy_hms(timestamp),
    birth_date = dmy(birth_date),
    age = scaler:::age(birth_date, timestamp),
    ethnicity = factor(
      ethnicity,
      levels = c(
        "Indígena",
        "Preta",
        "Parda",
        "Amarela",
        "Branca"
      ),
      ordered = TRUE
    ),
    education = factor(
      education,
      levels = c(
        "Não frequentou a escola",
        "Fundamental incompleto",
        "Fundamental completo",
        "Ensino médio incompleto",
        "Ensino médio completo",
        "Ensino superior incompleto",
        "Ensino superior completo",
        "Mestrado incompleto",
        "Mestrado completo",
        "Doutorado incompleto",
        "Doutorado completo",
        "Pós-doutorado incompleto",
        "Pós-doutorado completo"
      ),
      ordered = TRUE
    ),
    gestations = case_match(
      gestations,
      c("Sim", "0") ~ "1",
      "Não" ~ "0",
      .default = gestations
    ),
    deliveries = case_when(
      is.na(deliveries) ~ "0",
      TRUE ~ deliveries
    ),
    abortions = case_when(
      is.na(abortions) ~ "0",
      TRUE ~ abortions
    )
  ) |>
  mutate(
    across(
      .cols = all_of(
        c(
          "weight_before", "weight_current", "height",
          "family_income", "gestations", "deliveries",
          "abortions"
        )
      ),
      .fns = as.numeric
    )
  ) |>
  mutate(
    across(
      .cols = all_of(
        c("health_plan", "solo", "exercise", "work", "study")
      ),
      .fns = function(x) {
        case_match(
          x,
          "Sim" ~ TRUE,
          "Não" ~ FALSE
        )
      }
    )
  ) |>
  mutate(
    gestations = case_when(
      id == "ae5fc5cd" ~ 3,
      TRUE ~ gestations
    ),
  ) |>
  mutate(
    bmi_before = weight_before / ((height / 100)^2),
    bmi_current = weight_current / ((height / 100)^2)
  ) |>
  dplyr::select(-cpf) |>
  relocate(
    id, timestamp, birth_date, age, weight_before, weight_current, height, bmi_before, bmi_current, family_income
  )

field_form_data
```

## Getting Data from OSF

```{r}
data_dir <- here("data")
```

```{r}
if (!dir.exists(data_dir)) dir.create(data_dir)
```

```{r}
osf_processed_data_id <- "a2dsw"
```

```{r}
#| eval: false

osf_processed_data_id |>
  osf_retrieve_node() |>
  osf_ls_files(n_max = Inf) |>
  filter(name == "actigraphy") |>
  pull(id) |>
  osf_retrieve_file() |>
  osf_ls_files(n_max = Inf) |>
  filter(str_detect(name, "actigraphy-processed-data")) |>
  osf_download(
    path = data_dir,
    conflicts = "overwrite",
    progress = TRUE
  )
```

## Decrypt Data from OSF

```{r}
data_dir |>
  unlock_dir(
    private_key = private_key_path,
    password = password
  )
```

## Import and Process the OSF Data

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = ".txt$"
  )
```

```{r}
cli_progress_bar(total = length(files), clear = FALSE)

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.txt")

  i_ga_start <-
    control_data |>
    filter(id == i_id) |>
    pull(ga_start)

  i_data <-
    i |>
    read_acttrust(tz = "America/Sao_Paulo") |>
    shush() |>
    mutate(
      ga =
        ga_point(
          i_ga_start,
          timestamp
        ) |>
        as.numeric() |>
        as.duration() |>
        add(as_hms(timestamp) |> as.numeric() |> as.duration()),
      ga_week =
        ga |>
        as.numeric() |>
        divide_by(as.numeric(ddays(7))) |>
        as.integer()
    )

  i_data |>
    write_rds(
      here("data", paste0(i_id, "_actigraphy-processed-data.rds"))
    )

  cli_progress_update()
}

cli_progress_done()
```

## Compute SRI by Gestational Week

Exclusion criteria:

(2025-09-19) n = 44

- 5 days (drops 6) + 75% (drops 11): 27
- 5 days (drops 6) + 62.5% (drops 2): 36
- 4 days (drops 3) + 62.5% (drops 2): 39 # Ok
- 4 days (drops 3) + 50% (drops 1): 40 # Ok

```{r}
min_days <- 4
min_valid_data <- 0.5 # By `sri` and gestational age (they are related)
```

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_actigraphy-processed-data.rds$"
  )

old_files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "sri"
  )

if (length(old_files) > 0) file_delete(old_files)
```

```{r}
cli_progress_bar(total = length(files), clear = FALSE)

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.rds")

  i_data <-
    i |>
    read_rds() |>
    as_tibble() |>
    group_by(ga_week) |>
    mutate(
      ga_week_available_days = (n() * 60) / as.numeric(ddays(1))
    ) |>
    ungroup(ga_week) |>
    filter(ga_week_available_days >= min_days) |>
    as_tsibble(index = timestamp)

  if (nrow(i_data) == 0) {
    cli_alert_info(
      paste0(
        "{.strong {col_red(i_id)}} was dropped because it has no gestational ",
        "week with at least {min_days} days of data."
      )
    )

    cli_progress_update()

    next
  }

  i_sri_data <- tibble()

  for (j in unique(i_data$ga_week)) {
    j_data <- i_data |> filter(ga_week == j)
    j_data_first_index <- which(i_data$ga_week == j)[1]

    if (j_data_first_index > 1) {
      j_data <-
        i_data |>
        slice(seq(j_data_first_index - 1440, j_data_first_index - 1)) |>
        as_tibble() |>
        bind_rows(j_data |> as_tibble()) |>
        as_tsibble(index = timestamp)
    }

    i_sri_data <-
      i_sri_data |>
      bind_rows(
        j_data |>
          sri(
            sleeping_states = c(1, 2),
            awake_states = 0,
            min_data = min_valid_data
          ) |>
          mutate(
            id = i_id,
            ga_week = j
          ) |>
          as_tibble()
      )
  }

  i_sri_data <-
    i_sri_data |>
    drop_na(sri) |>
    group_by(ga_week) |>
    mutate(dummy = n() >= (1440 * min_valid_data)) |>
    ungroup() |>
    filter(dummy) |>
    dplyr::select(-dummy)

  if (nrow(i_sri_data) == 0) {
    cli_alert_info(
      paste0(
        "{.strong {col_red(i_id)}} was dropped because it has no gestational ",
        "week with at least {round(min_valid_data * 100, 2)}% of SRI data."
      )
    )

    cli_progress_update()

    next
  }

  i_sri_data |> write_rds(here("data", paste0(i_id, "_sri-data.rds")))

  cli_progress_update()
}

cli_progress_done()
```

## Group SRI Data

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_sri-data.rds$"
  )
```

```{r}
sri_data <- tibble()

for (i in files) {
  sri_data <-
    i |>
    read_rds() |>
    mutate(
      time =
        time |>
        as.numeric() |>
        divide_by(60) |>
        as.integer() |>
        dminutes() |>
        as.numeric() |>
        as_hms()
    ) |>
    bind_rows(sri_data)
}

sri_data <-
  sri_data |>
  mutate(ga_week = as.factor(ga_week)) |>
  arrange(ga_week)
```

```{r}
sri_data
```

## Compute SRI Means By Gestational Week

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_sri-data.rds$"
  )
```

```{r}
for (i in files) {
  i_id <- str_remove(basename(i), "_sri-data.rds")

  i_data <-
    i |>
    read_rds() |>
    as_tibble() |>
    group_by(ga_week) |>
    summarize(sri = mean(sri, na.rm = TRUE)) |>
    mutate(id = i_id) |>
    dplyr::select(id, ga_week, sri)

  i_data |> write_rds(here("data", paste0(i_id, "_sri-mean-data.rds")))
}
```

## Group SRI Mean Data

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_sri-mean-data.rds$"
  )
```

```{r}
sri_mean_data <- tibble()

for (i in files) {
  sri_mean_data <-
    i |>
    read_rds(i) |>
    bind_rows(sri_mean_data)
}

sri_mean_data <-
  sri_mean_data |>
  mutate(ga_week = as.factor(ga_week)) |>
  arrange(ga_week)
```

```{r}
sri_mean_data
```

## Compute State Proportions

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_actigraphy-processed-data.rds$"
  )
```

```{r}
cli_progress_bar(
  total = length(files),
  clear = FALSE
)

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.txt")

  i_data <-
    i |>
    read_acttrust(tz = "America/Sao_Paulo") |>
    shush() |>
    state_prop() |>
    mutate(id = i_id)

  i_data |> write_rds(here("data", paste0(i_id, "_state-prop-data.rds")))

  cli_progress_update()
}

cli_progress_done()
```

```{r}
i_data |>
  mutate(per = prop * 100) |>
  ggplot(aes(x = time, y = per)) +
  geom_smooth(color = "#FC2913") +
  labs(
    x = "Time of day (Hour)",
    y = "Percentage of time asleep (%)",
  ) +
  scale_x_time(
    breaks = breaks_width("6 hours"),
    labels = label_time("%-H") # Use "%#H" for Windows
  ) +
  scale_y_continuous(limits = c(NA, 100))
```

## Explore Model Data

### SRI by Gestational Age Week

```{r}
sri_mean_data |>
  mutate(ga_week = ga_week |> as.character() |> as.numeric()) |>
  filter(between(ga_week, 36, 39)) |>
  ggplot(aes(x = ga_week, y = sri)) +
  geom_point() +
  geom_smooth(
    method = "lm",
    formula = y ~ x,
    color = "red"
  ) +
  labs(
    x = "Gestational Age Week",
    y = "Sleep Regularity Index (SRI)",
  )
  theme(legend.position = "none")
```

```{r}
sri_mean_data |>
  mutate(ga_week = ga_week |> as.character() |> as.numeric()) |>
  filter(between(ga_week, 36, 39)) |>
  mutate(ga_week = factor(ga_week)) |>
  ggplot(aes(x = sri, y = ga_week, fill = ga_week)) +
  geom_boxplot() +
  coord_flip() +
  # scale_y_discrete(limits = rev) +
  labs(
    x = "Sleep Regularity Index (SRI)",
    y = "Gestational Age Week",
  ) +
  scale_color_viridis_d() +
  theme(legend.position = "none")
```

```{r}
sri_mean_data |>
  mutate(ga_week = ga_week |> as.character() |> as.numeric()) |>
  filter(between(ga_week, 36, 39)) |>
  slice_sample(prop = 0.5) |>
  ggplot(aes(x = ga_week, y = sri, color = id)) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  geom_smooth(
    mapping = aes(x = ga_week, y = sri),
    method = "lm",
    formula = y ~ x,
    se = FALSE,
    color = "black"
  ) +
  labs(
    x = "Gestational Age Week",
    y = "Sleep Regularity Index (SRI)",
    color = NULL
  )
  # theme(legend.position = "none")
```

## Model

### Model Data

```{r}
sri_mean_data |> summarize(n = unique(id) |> length(), .by = ga_week)
```

```{r}
ga_lim <- c(36, 39)

# ga_week_num <- sri_mean_data$ga_week |> as.character() |> as.integer()
# ga_lim <- c(min(ga_week_num),  max(ga_week_num))

ga_lim
```

```{r}
model_data <-
  sri_mean_data |>
  mutate(
    ga_week =
      ga_week |>
      as.character() |>
      as.numeric()
  ) |>
  filter(between(ga_week, ga_lim[1], ga_lim[2])) |>
  mutate(
    ga_week_centered =
      ga_week |>
      scale(center = TRUE, scale = FALSE)
  ) |>
  group_by(ga_week) |>
  mutate(n = n()) |>
  ungroup() |>
  left_join(
    field_form_data |> dplyr::select(-timestamp),
    by = "id"
  )
```

```{r}
model_data |> nrow()
```

```{r}
model_data |> pull(id) |> unique() |> length()
```

```{r}
model_data_weeks <-
  model_data |>
  pull(ga_week) |>
  unique() |>
  length()

model_data_weeks
```

```{r}
model_data |> summarize(n = n(), .by = id) |> arrange(n) |> print(n = Inf)
```

```{r}
model_data
```

### Model Sample Characteristics

```{r}
ids <- model_data |> pull(id) |> unique()

files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = paste0(ids, "_actigraphy-processed-data.rds$", collapse = "|")
  )

days_by_id <- tibble()

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.rds")
  i_data <- i |> read_rds()
  i_start <- i_data |> pull(timestamp) |> first()
  i_end <- i_data |> pull(timestamp) |> last()

  days_by_id <-
    tibble(
      id = i_id,
      days = (i_end - i_start) |> as.numeric()
    ) |>
    bind_rows(days_by_id)
}

days_by_id <- days_by_id |> arrange(id)

days_by_id |> print(n = Inf)
days_by_id |> pull(days) |> summary()
```

### Generalized Estimating Equations (GEE)

```{r}
#| output: false

library(geepack)
library(glmtoolbox)
library(performance)
```

```{r}
model_data_gee <-
  model_data |>
  mutate(id = id |> as.factor() |> as.numeric()) |>
  arrange(id, ga_week)
```

```{r}
model_data_gee |> summarize(n = n(), .by = id) |> arrange(n) |> print(n = Inf)
```

```{r}
model_gee <- geeglm(
  sri ~ ga_week_centered,
  family = gaussian,
  id = id,
  weights = n,
  data = model_data_gee,
  corstr = "exchangeable"
)

model_gee
```

```{r}
summary(model_gee)
```

### One-Tailed p-value

```{r}
coefs <- summary(model_gee)$coefficients
beta  <- coefs["ga_week_centered", "Estimate"]
se    <- coefs["ga_week_centered", "Std.err"]

p_one_tailed <- pnorm(z)

p_one_tailed
```

### Model Diagnostics

```{r}
scale_parameter <- summary(model_gee)$dispersion[[1]]
scale_parameter_se <- summary(model_gee)$dispersion[[2]]

sd_residuals <- sqrt(scale_parameter)

sd_residuals
```

```{r}
library(plotr) # github.com/danielvartan/plotr

tibble(x = residuals(model_gee)[, 1]) |>
  plotr:::plot_qq("x")
```

```{r}
library(rutils) # github.com/danielvartan/rutils

tibble(x = residuals(model_gee)[, 1]) |> rutils:::normality_summary("x")
```

```{r}
check_model(model_gee)
```

### Standardized Effect by Week

$$
d_{Total} = \cfrac{\beta}{\text{SD}(Y)}
$$

```{r}
beta <- coef(model_gee)["ga_week_centered"]
sd_residuals <- sqrt(scale_parameter)

d_by_week <- beta / sd_residuals

d_by_week
```

```{r}
se_beta <- summary(model_gee)$coefficients["ga_week_centered", "Std.err"]

ci_lower <- (beta - (1.96 * se_beta)) / sd_residuals
ci_upper <- (beta + (1.96 * se_beta)) / sd_residuals

c(ci_lower, ci_upper)
```

```{r}
library(effectsize)

interpret_cohens_d(d_by_week)
```

### Standardized Effect by 3rd Trimester

$$
d_{Total} = \cfrac{\beta \times \Delta\text{Weeks}}{\text{SD}(Y)}
$$

```{r}
d_by_week * 10
```

```{r}
library(effectsize)

interpret_cohens_d(d_total)
```

## *A Posteriori* Power Analysis

```{r}
set.seed(2025)
```

```{r}
n_clusters <- summary(model_gee)$clusz |> length()
cluster_size <- summary(model_gee)$clusz |> mean() |> floor()
alpha <- x$corr[[1]]
beta <- coefficients(model_gee)[2]
sigma <- summary(model_gee)$dispersion[[1]] |> sqrt()

n_sim <- 1000
rejects <- 0

for (i in seq_len(n_sim)){
  sim_data <- tibble(
    id = seq_len(n_clusters) |> rep(each = cluster_size),
    x = seq_len(cluster_size) |> rep(n_clusters)
  )

  correlated_errors <-
    rep(
      rnorm(n_clusters, 0, sigma * sqrt(alpha)),
      each = cluster_size
    ) |>
    add(
      rnorm(n_clusters * cluster_size, 0, sigma * sqrt(1 - alpha))
    )

  sim_data <- sim_data |> mutate(y = beta * x + correlated_errors)

  fit <- geeglm(
    y ~ x,
    family = gaussian,
    id = id,
    data = sim_data,
    corstr = "exchangeable"
  )

  p_value <- summary(fit)$coefficients[2,4]

  if (p_value < 0.05) rejects <- rejects + 1
}

power_estimate <- rejects / n_sim

power_estimate
```
