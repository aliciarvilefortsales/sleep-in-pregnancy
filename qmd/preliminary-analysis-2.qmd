---
execute:
  eval: false
---

# Preliminary Analysis 2

```{r}
#| label: setup
#| include: false

source(here::here("R", "_setup.R"))
```

## Set the Environment

```{r}
#| output: false

library(actverse) # github.com/danielvartan/actverse
library(askpass)
library(broom)
library(checkmate)
library(cli)
library(effectsize)
library(fs)
library(ggplot2)
library(googlesheets4)
library(here)
library(hms)
library(infer)
library(janitor)
library(lockr) # github.com/danielvartan/lokcr
library(lubridate)
library(lubritime) # github.com/danielvartan/lubritime
library(magrittr)
library(orbis) # github.com/danielvartan/orbis
library(osfr)
library(parsnip)
library(plotr) # github.com/danielvartan/plotr
library(psychometric)
library(pwr)
library(pwrss)
library(readr)
library(rutils) # github.com/danielvartan/rutils
library(scaler) # github.com/danielvartan/scaler
library(scales)
library(sodium)
library(stats)
library(stringr)
library(summarytools)
library(tidyr)
library(tsibble)
```

```{r}
source(here::here("R", "anonymize_id.R"))
source(here::here("R", "ga.R"))
```

## Setting Parameters

```{r}
#| eval: false
#| output: false

prettycheck:::assert_interactive()

googlesheets4::gs4_auth()
```

```{r}
#| eval: false

prettycheck:::assert_interactive()

osf_auth()
```

```{r}
private_key_path <- here::here("_ssh", "id_rsa")
```

```{r}
#| eval: false

password <- askpass::askpass()
```

```{r}
#| eval: false

salt <- askpass::askpass()
```

```{r}
public_key_path <- here::here("_ssh", "id_rsa.pub")
```

## Get Data from Google Sheets

```{r}
#| output: false

control_form <- googlesheets4::read_sheet(
  ss = "13wtDr4fRD1wJSM-qdLOdGSchF8oXU1bG0Jtccu24GhY",
  sheet = "Dataset",
  col_types = "c"
)
```

```{r}
#| output: false

field_form <- googlesheets4::read_sheet(
  ss = "1tY_TT0nPXFsErYQS2VED0-hqTzgHudA9BfhRhYG19fw",
  sheet = "Dataset",
  col_types = "c"
)
```

## Process the Google Sheets Data

```{r}
control_data <-
  control_form |>
  `names<-`(paste0("X", seq_along(control_form))) |>
  dplyr::select(X5, X6, X12, X39, X40) |>
  dplyr::rename(
    cpf = X5,
    id = X6,
    birth_center_delivery = X12,
    ultrasound_date = X40,
    ultrasound_ga = X39
  ) |>
  dplyr::mutate(
    birth_center_delivery = dplyr::case_when(
      tolower(trimws(birth_center_delivery)) == "sim" ~ TRUE,
      tolower(trimws(birth_center_delivery)) == "não" ~ FALSE,
      TRUE ~ NA
    ),
    ultrasound_date = ymd(ultrasound_date),
    ga_start = if_else(
      is.na(ultrasound_ga),
      as.Date(NA),
      ga_start(
        ultrasound = ultrasound_date,
        ga =
          str_extract(ultrasound_ga, "^\\d{1,2}") |>
          as.integer() |>
          weeks() |>
          add(
            str_extract(ultrasound_ga, "\\d(?= di)") |>
            as.integer() |>
            lubridate::days()
          )
      )
    )
  ) |>
  dplyr::select(cpf, id, birth_center_delivery, ga_start)

control_data
```

```{r}
field_form_data <-
  field_form |>
  `names<-`(paste0("X", seq_along(field_form))) |>
  dplyr::select(
    X1, X4, X5, X11, X91, X92, X95, X96, X97, X99, X101, X102, X106, X119,
    X118, X125, X126
  ) |>
  dplyr::rename(
    timestamp = X1,
    birth_date = X4,
    cpf = X5,
    weight_before = X96,
    weight_current = X95,
    height = X97,
    ethnicity = X106,
    education = X118,
    family_income = X99,
    health_plan = X101,
    solo = X102,
    exercise = X119,
    work = X92,
    study = X91,
    gestations = X11,
    deliveries = X125,
    abortions = X126
  ) |>
  dplyr::mutate(
    id = anonymize_id(cpf, salt),
    timestamp = lubridate::mdy_hms(timestamp),
    birth_date = lubridate::dmy(birth_date),
    age = scaler:::age(birth_date, timestamp),
    ethnicity = factor(
      ethnicity,
      levels = c(
        "Indígena",
        "Preta",
        "Parda",
        "Amarela",
        "Branca"
      ),
      ordered = TRUE
    ),
    education = factor(
      education,
      levels = c(
        "Não frequentou a escola",
        "Fundamental incompleto",
        "Fundamental completo",
        "Ensino médio incompleto",
        "Ensino médio completo",
        "Ensino superior incompleto",
        "Ensino superior completo",
        "Mestrado incompleto",
        "Mestrado completo",
        "Doutorado incompleto",
        "Doutorado completo",
        "Pós-doutorado incompleto",
        "Pós-doutorado completo"
      ),
      ordered = TRUE
    ),
    gestations = dplyr::case_match(
      gestations,
      c("Sim", "0") ~ "1",
      "Não" ~ "0",
      .default = gestations
    ),
    deliveries = dplyr::case_when(
      is.na(deliveries) ~ "0",
      TRUE ~ deliveries
    ),
    abortions = dplyr::case_when(
      is.na(abortions) ~ "0",
      TRUE ~ abortions
    )
  ) |>
  dplyr::mutate(
    dplyr::across(
      .cols = dplyr::all_of(
        c(
          "weight_before", "weight_current", "height",
          "family_income", "gestations", "deliveries",
          "abortions"
        )
      ),
      .fns = as.numeric
    )
  ) |>
  dplyr::mutate(
    dplyr::across(
      .cols = dplyr::all_of(
        c("health_plan", "solo", "exercise", "work", "study")
      ),
      .fns = function(x) {
        dplyr::case_match(
          x,
          "Sim" ~ TRUE,
          "Não" ~ FALSE
        )
      }
    )
  ) |>
  dplyr::mutate(
    gestations = dplyr::case_when(
      id == "ae5fc5cd" ~ 3,
      TRUE ~ gestations
    ),
  ) |>
  dplyr::mutate(
    bmi_before = weight_before / ((height / 100)^2),
    bmi_current = weight_current / ((height / 100)^2)
  ) |>
  dplyr::select(-cpf) |>
  dplyr::relocate(
    id, timestamp, birth_date, age, weight_before, weight_current, height, bmi_before, bmi_current, family_income
  )

field_form_data
```

## Getting Data from OSF

```{r}
data_dir <- here::here("data")
```

```{r}
if (!dir.exists(data_dir)) dir.create(data_dir)
```

```{r}
osf_processed_data_id <- "a2dsw"
```

```{r}
#| eval: false

osf_processed_data_id |>
  osf_retrieve_node() |>
  osf_ls_files(n_max = Inf) |>
  filter(name == "actigraphy") |>
  pull(id) |>
  osf_retrieve_file() |>
  osf_ls_files(n_max = Inf) |>
  filter(stringr::str_detect(name, "actigraphy-processed-data")) |>
  osf_download(
    path = data_dir,
    conflicts = "overwrite",
    progress = TRUE
  )
```

## Decrypt Data from OSF

```{r}
data_dir |>
  unlock_dir(
    private_key = private_key_path,
    password = password
  )
```

## Sample Characteristics

## Import and Transform the Data

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = ".txt$"
  )
```

```{r}
cli_progress_bar(total = length(files), clear = FALSE)

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.txt")

  i_ga_start <-
    control_data |>
    filter(id == i_id) |>
    pull(ga_start)

  i_data <-
    i |>
    read_acttrust(tz = "America/Sao_Paulo") |>
    shush() |>
    mutate(
      ga =
        ga_point(
          i_ga_start,
          timestamp
        ) |>
        as.numeric() |>
        as.duration() |>
        add(as_hms(timestamp) |> as.numeric() |> as.duration()),
      ga_week =
        ga |>
        as.numeric() |>
        divide_by(as.numeric(ddays(7))) |>
        as.integer()
    )

  i_data |>
    write_rds(
      here("data", paste0(i_id, "_actigraphy-processed-data.rds"))
    )

  cli_progress_update()
}

cli_progress_done()
```

## Compute SRI By Gestational Week

Critérios de exclusão:

- Semanas com menos de 5 dias
- Semanas com menos de 75% de disponibilidade de dados SRI

Passos:

1. Calcular a IG em cada ponto do dado actigráfico.
2. Remover semanas com menos de 5 dias
3. Calcular o SRI para cada semana (summarize)
4. Transformar em NA SRIs com proporção de valores de concordâncias menores que `0.75`.
5. Remover semanas com menos de 75% de disponibilidade de dados SRI.
6. Tirar a média do SRI por semana (colunas: id, ig, sri)
7. Juntar os dados de todas as gestantes.
8. ANOVA do `sri` por grupos de IG

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_actigraphy-processed-data.rds$"
  )

old_files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "sri"
  )

if (length(old_files) > 0) file_delete(old_files)
```

Exclusion criteria:

(2025-08-28) n = 40

- 5 days (drops 6) + 75% (drops 12): 22
- 5 days (drops 6) + 62.5% (drops 4): 30
- 4 days (drops 3) + 50% (drops 1): 36
- 4 days (drops 3) + 50% (drops 1): 36
- 3 days (drops 3) + 50% (drops 1): 36

+ Sample potential

- With the voluntaries: 2
- Not read: 1 (Mariana) + 2 (Casa Angela): 3
- Not processed: 2

```{r}
min_days <- 4
min_valid_data <- 0.5 # By gestational age
```

```{r}
cli_progress_bar(total = length(files), clear = FALSE)

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.rds")

  i_data <-
    i |>
    read_rds() |>
    as_tibble() |>
    group_by(ga_week) |>
    mutate(
      ga_week_available_days = (n() * 60) / as.numeric(ddays(1))
    ) |>
    ungroup(ga_week) |>
    filter(ga_week_available_days >= min_days) |>
    as_tsibble(index = timestamp)

  if (nrow(i_data) == 0) {
    cli_alert_info(
      paste0(
        "{.strong {col_red(i_id)}} was dropped because it has no gestational ",
        "week with at least {min_days} days of data."
      )
    )

    cli_progress_update()

    next
  }

  i_sri_data <- tibble()

  for (j in unique(i_data$ga_week)) {
    j_data <- i_data |> filter(ga_week == j)
    j_data_first_index <- which(i_data$ga_week == j)[1]

    if (j_data_first_index > 1) {
      j_data <-
        i_data |>
        slice(seq(j_data_first_index - 1440, j_data_first_index - 1)) |>
        as_tibble() |>
        bind_rows(j_data |> as_tibble()) |>
        as_tsibble(index = timestamp)
    }

    i_sri_data <-
      i_sri_data |>
      bind_rows(
        j_data |>
          sri(
            sleeping_states = c(1, 2),
            awake_states = 0,
            min_data = min_valid_data
          ) |>
          mutate(
            id = i_id,
            ga_week = j
          ) |>
          as_tibble()
      )
  }

  i_sri_data <-
    i_sri_data |>
    drop_na(sri) |>
    group_by(ga_week) |>
    mutate(dummy = n() >= (1440 * min_valid_data)) |> # 1080
    ungroup() |>
    filter(dummy) |>
    dplyr::select(-dummy)

  if (nrow(i_sri_data) == 0) {
    cli_alert_info(
      paste0(
        "{.strong {col_red(i_id)}} was dropped because it has no gestational ",
        "week with at least {round(min_valid_data * 100, 2)}% of SRI data."
      )
    )

    cli_progress_update()

    next
  }

  i_sri_data |> write_rds(here("data", paste0(i_id, "_sri-data.rds")))

  cli_progress_update()
}

cli_progress_done()
```

## Group SRI Data

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_sri-data.rds$"
  )
```

```{r}
sri_data <- tibble()

for (i in files) {
  sri_data <-
    i |>
    read_rds() |>
    mutate(
      time =
        time |>
        as.numeric() |>
        divide_by(60) |>
        as.integer() |>
        dminutes() |>
        as.numeric() |>
        as_hms()
    ) |>
    bind_rows(sri_data)
}

sri_data <-
  sri_data |>
  mutate(ga_week = as.factor(ga_week)) |>
  arrange(ga_week)
```

```{r}
sri_data
```

## Compute SRI Means By Gestational Week

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_sri-data.rds$"
  )
```

```{r}
for (i in files) {
  i_id <- str_remove(basename(i), "_sri-data.rds")

  i_data <-
    i |>
    read_rds() |>
    as_tibble() |>
    group_by(ga_week) |>
    summarize(sri = mean(sri, na.rm = TRUE)) |>
    mutate(id = i_id) |>
    dplyr::select(id, ga_week, sri)

  i_data |> write_rds(here("data", paste0(i_id, "_sri-mean-data.rds")))
}
```

## Group SRI Mean Data

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_sri-mean-data.rds$"
  )
```

```{r}
sri_mean_data <- tibble()

for (i in files) {
  sri_mean_data <-
    i |>
    read_rds(i) |>
    bind_rows(sri_mean_data)
}

sri_mean_data <-
  sri_mean_data |>
  mutate(ga_week = as.factor(ga_week)) |>
  arrange(ga_week)
```

```{r}
sri_mean_data
```

## Compute State Proportions

```{r}
files <-
  dir_ls(
    path = here("data"),
    type = "file",
    regexp = "_actigraphy-processed-data.rds$"
  )
```

```{r}
cli_progress_bar(
  total = length(files),
  clear = FALSE
)

for (i in files) {
  i_id <- str_remove(basename(i), "_actigraphy-processed-data.txt")

  i_data <-
    i |>
    read_acttrust(tz = "America/Sao_Paulo") |>
    shush() |>
    state_prop() |>
    mutate(id = i_id)

  i_data |> write_rds(here("data", paste0(i_id, "_state-prop-data.rds")))

  cli_progress_update()
}

cli_progress_done()
```

```{r}
i_data |>
  mutate(per = prop * 100) |>
  ggplot(ggplot2::aes(x = time, y = per)) +
  geom_smooth(color = "#FC2913") +
  labs(
    x = "Time of day (Hour)",
    y = "Percentage of time asleep (%)",
  ) +
  scale_x_time(
    breaks = breaks_width("6 hours"),
    labels = label_time("%-H") # Use "%#H" for Windows
  ) +
  scale_y_continuous(limits = c(NA, 100))
```

## Explore Model Data

### SRI by Gestational Age Week

```{r}
sri_data |>
  ggplot(aes(x = sri, fill = ga_week)) +
  geom_boxplot() +
  coord_flip() +
  labs(
    x = "Sleep Regularity Index (SRI)",
    y = "Gestational Age Week"
  )
```

```{r}
sri_data |>
  ggplot(aes(x = sri, y = ga_week, color = ga_week)) +
  geom_point() +
  geom_jitter(width = 0.1, height = 0) +
  labs(
    x = "Sleep Regularity Index (SRI)",
    y = "Gestational Age Week"
  )
```

## SRI Over Time

(all sample combined)

## Models

$$
\begin{cases}
  \text{H}_{0}: \rho \geq 0 \\
  \text{H}_{a}: \rho < 0
\end{cases}
$$

```{r}
sri_mean_data |> summarize(n = unique(id) |> length(), .by = ga_week)
```

```{r}
ga_lim <- c(36, 39)

# ga_week_num <- sri_mean_data$ga_week |> as.character() |> as.integer()
# ga_lim <- c(min(ga_week_num),  max(ga_week_num))

ga_lim
```

```{r}
model_data <-
  sri_mean_data |>
  mutate(
    ga_week =
      ga_week |>
      as.character() |>
      as.numeric(),
    ga_week_centered =
      ga_week |>
      scale(center = TRUE, scale = FALSE)
  ) |>
  filter(between(ga_week, ga_lim[1], ga_lim[2])) |>
  group_by(ga_week) |>
  mutate(n = n()) |>
  ungroup() |>
  left_join(
    field_form_data |> dplyr::select(-timestamp),
    by = "id"
  )
```

```{r}
model_data |> nrow()
```

```{r}
model_data |> pull(id) |> unique() |> length()
```

```{r}
model_data_weeks <-
  model_data |>
  pull(ga_week) |>
  unique() |>
  length()

model_data_weeks
```

```{r}
model_data |> summarize(n = n(), .by = id) |> arrange(n)
```

```{r}
model_data
```

### Pearson Correlation

```{r}
cor.test(
  x = model_data$ga_week_centered,
  y = model_data$sri,
  alternative = "less"
)
```

### Weighted Pearson Correlation

```{r}
#| output: false

library(weights)
```

```{r}
model_wtd_cor <- wtd.cor(
  x = model_data$ga_week_centered,
  y = model_data$sri,
  weight = model_data$n
)

model_wtd_cor
```

```{r}
t_obs <- model_wtd_cor[, 3]
df <- length(model_data) - 1

pt(t_obs, df)
```

### Generalized Estimating Equations (GEE)

```{r}
#| output: false

library(geepack)
library(glmtoolbox)
library(performance)
```

```{r}
model_data_gee <-
  model_data |> 
  mutate(id = id |> as.factor() |> as.numeric()) |>
  arrange(id, ga_week)
```

```{r}
model_data_gee |> summarize(n = n(), .by = id) |> arrange(n)
```

```{r}
model_gee <- geeglm(
  sri ~ ga_week_centered, 
  family = gaussian,
  id = id, # ga_week,
  weights = n,
  data = model_data_gee,
  corstr = "exchangeable"
)

model_gee
```

```{r}
summary(model_gee)
```

```{r}
coefs <- summary(model_gee)$coefficients
beta  <- coefs["ga_week_centered", "Estimate"]
se    <- coefs["ga_week_centered", "Std.err"]

z     <- beta / se

p_one_sided <- pnorm(z)

p_one_sided
```

```{r}
library(plotr) # github.com/danielvartan/plotr

tibble(x = residuals(model_gee)[, 1]) |> 
  plotr:::plot_qq("x")
```

```{r}
library(rutils) # github.com/danielvartan/rutils

tibble(x = residuals(model_gee)[, 1]) |> rutils:::normality_summary("x")
```

```{r}
check_model(model_gee)
```

#### Effect Size by Week

$$
d_{Total} = \cfrac{\beta}{\text{SD}(Y)}
$$

```{r}
beta <- coef(model_gee)["ga_week_centered"]
sd_y <- model_data |> pull(sri) |> sd()

d_by_week <- beta / sd_y

d_by_week
```

```{r}
se_beta <- summary(model_gee)$coefficients["ga_week_centered", "Std.err"]

ci_lower <- (beta - (1.96 * se_beta)) / sd_y
ci_upper <- (beta + (1.96 * se_beta)) / sd_y

c(ci_lower, ci_upper)
```

```{r}
library(effectsize)

interpret_cohens_d(d_total)
```

#### Effect Size for Delta Week

$$
d_{Total} = \cfrac{\beta \times \Delta\text{Weeks}}{\text{SD}(Y)}
$$

```{r}
weeek_min <- min(model_data$ga_week)
week_max <- max(model_data$ga_week)

c(weeek_min, week_max)
```

```{r}
beta <- coef(model_gee)["ga_week_centered"]
delta_weeks <- week_max - weeek_min
sd_y <- model_data |> pull(sri) |> sd()


d_total <- (beta * delta_weeks) / sd_y

d_total
```

```{r}
se_beta <- summary(model_gee)$coefficients["ga_week_centered", "Std.err"]
se_total <- se_beta * delta_weeks

ci_lower <- ((beta * delta_weeks) - 1.96 * se_total) / sd_y
ci_upper <- ((beta * delta_weeks) + 1.96 * se_total) / sd_y

c(ci_lower, ci_upper)
```

```{r}
library(effectsize)

interpret_cohens_d(d_total)
```

#### *A Posteriori* Power Analysis: **ESTIMATE**

> Fazer análise de poder por simulação!!!

```{r}
library(pwr)
```

```{r}
n_clusters <- model_data_gee |> pull(id) |> unique() |> length()

n_clusters
```

```{r}
pwr.t.test(
  n = n_clusters,
  d = d_total,
  sig.level = 0.05,
  power = NULL,
  type = "paired",
  alternative = "less"
)
```

### Linear Model (LM)

```{r}
model_lm <- lm(
  sri ~ ga_week_centered,
  data = model_data,
  weights = n
)
```

```{r}
sm <- summary(model_lm)

sm
```

```{r}
t_obs <- sm$coefficients["ga_week_centered", "t value"]
df <- length(model_data) - 1

pt(t_obs, df)
```

## Linear Model (LM) with Model Selection

```{r}
#| output: false

library(MuMIn)
```

```{r}
model_data_mumin <-
  model_data |>
    dplyr::select(-education) |>
    drop_na(bmi_current, family_income)
```

```{r}
model_lm_full <- lm(
  sri ~ ga_week_centered + age + weight_current + bmi_current + family_income +
  ethnicity + gestations + deliveries + abortions + solo + work,
  data = model_data_mumin,
  na.action = na.fail
)
```

```{r}
model_lm_full <- lm(
  sri ~ ga_week_centered + age + weight_current + bmi_current + family_income +
  ethnicity + gestations + deliveries + abortions + solo + work,
  data = model_data_mumin,
  na.action = na.fail
)
```

```{r}
sm <- summary(model_lm_full)

sm
```

```{r}
x <- dredge(model_lm_full)
```

### Linear Mixed Model (LMM)

```{r}
library(lme4)
library(lmerTest)
library(emmeans)
library(pbkrtest)
library(performance)
library(see)
```

```{r}
m_lmm <- lmer(
  sri ~ ga_week_centered + (1 | id),
  data = model_data
)
```

```{r}
sm <- summary(m_lmm)

sm
```

```{r}
t_obs <- sm$coefficients["ga_week_centered", "t value"]
df <- sm$coefficients["ga_week_centered", "df"]

pt(t_obs, df)
```

```{r}
check_model(m_lmm)
```

```{r}
emm <- emmeans(
  m_lmm, ~ ga_week_centered,
  at = list(ga_week_centered = 33:40)
)
```

```{r}
plot(emm, xlim = c(0, 100))
```

```{r}
pred <- emm |> as_tibble()
```

```{r}
model_data |>
  ggplot(aes(x = ga_week, y = sri, color = id)) +
  # geom_line(alpha = 0.3) +
  geom_point(alpha = 0.3) +
  # geom_line(
  #   data = pred,
  #   mapping = aes(x = ga_week_centered, y = emmean),
  #   color = "blue",
  #   size = 1.2
  # ) +
  # geom_ribbon(
  #   data = pred,
  #   mapping = aes(ymin = lower.CL, ymax = upper.CL),
  #   alpha = 0.2,
  #   fill = "blue"
  # ) +
  labs(
    x = "Semana gestacional",
    y = "SRI (%)",
    title =
    "Tendência do Índice de Regularidade do Sono (SRI)"
  )
```

```{r}
model_data |>
  ggplot(aes(x = ga_week, y = sri)) +
  geom_smooth(alpha = 0.3, method = "gam") +
  geom_point(alpha = 0.3)
```

```{r}
model_data |>
  ggplot(aes(x = ga_week, y = sri)) +
  geom_smooth(alpha = 0.3) +
  geom_point(alpha = 0.3)
```

### Effect Size

```{r}
model_fit$adj.r.squared
```

```{r}
model_fit$adj.r.squared |> interpret_r2(rules = "cohen1988")
```

```{r}
model_fit$adj.r.squared
```

```{r}
model_fit$adj.r.squared |> interpret_r2(rules = "cohen1988")
```

```{r}
delta <- model_fit$adj.r.squared - fit_restricted_stats$adj.r.squared

delta
```

```{r}
CI.Rsq(
  rsq = delta,
  n = model_data |> nrow(),
  k = 2
)
```

```{r}
delta |> interpret_r2(rules = "cohen1988")
```

### *A Posteriori* Power Analysis

```{r}
pwrss.f.reg(
  r2 = model_fit$adj.r.squared,
  k = 2,
  n = model_data |> nrow(),
  power = NULL,
  alpha = 0.05
)
```

## ANOVA Model

Critério de exclusão:

- Grupos de semanas gestacioanis com menos de 5 gestantes

```
Ho: 36 >= 37 >= 38 >= 39 >= ...
Ha: 36 < 37 < 38 < 39 < ...
```
- Fazer ANCOVA
- Ver outros modelos

```{r}
model_data <-
  sri_data |>
  group_by(ga_week) |>
  mutate(dummy = n() >= 5) |>
  ungroup(ga_week) |>
  filter(dummy) |>
  arrange(ga_week) |>
  dplyr::select(-dummy)
```

```{r}
model_data |> summarize(n = n(), .by = ga_week)
```

### *A Prioi* Power Analysis

```{r}
pwr_analysis <- pwr.anova.test(
  k = model_data |> pull(ga_week) |> unique() |> length(),
  f = 0.25, # Cohen's f for medium effect sizes
  sig.level = 0.05,
  power = 0.8
)
```

```{r}
pwr_analysis
```

```{r}
pwr_analysis |>
  plot.power.htest(
    xlab = "Sample size per group",
    ylab = "Power (1 - Beta)",
    main = NULL
  )
```

### Model Data

```{r}
observed_statistic <-
  model_data |>
  specify(sri ~ ga_week) |>
  hypothesize(null = "independence") |>
  calculate(stat = "F")

observed_statistic
```

```{r}
null_dist <-
  model_data |>
  specify(sri ~ ga_week) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "F")

null_dist
```

```{r}
null_dist |>
  visualize(method = "both") +
  shade_p_value(
    obs_stat = observed_statistic,
    direction = "greater"
  ) +
  labs(
    title = NULL,
    x = "F-statistic",
    y = "Frequency"
  )
```

```{r}
null_dist |>
  get_p_value(
    obs_stat = observed_statistic,
    direction = "right"
  )
```

```{r}
aov(sri ~ ga_week, data = model_data) |>
  TukeyHSD(conf.level = 0.95) |>
  tidy()
```

### Effect Size

```{r}
effect_size <-
  aov(sri ~ ga_week, data = model_data) |>
  cohens_f()

effect_size
```

```{r}
effect_size[[2]] |>
  f_to_eta2() |>
  interpret_eta_squared(rules = "cohen1992")
```

### *A Posteriori* Power Analysis

```{r}
groups_n <-
  model_data |>
  summarize(n = n(), .by = ga_week)

groups_n
```

```{r}
pwr.anova.test(
  k = nrow(groups_n),
  n = min(groups_n$n),
  f = effect_size[[2]],
  sig.level = 0.05
)
```
